{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost==0.81 pandas==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-api-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dropdown menu in top left, select:\n",
    "\n",
    "    Kernel --> Restart Kernel and Clear All Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data into [Google Cloud Storage](https://console.cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    1. Create a bucket in <a href=\"https://console.cloud.google.com/storage/\">cloud storage</a> to store the raw data in. Use no weird characters in the name. Remember the name of the bucket.\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    2. Create a folder named 'instacart' in the bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    3. Set parameters\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'sebastian-test-4321' # The name of the bucket created above\n",
    "PROJECT = 'avaus-academy' # Do not change\n",
    "REGION = 'us-central1' # Do not change\n",
    "LAB_ID = BUCKET.replace('-', '_').replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['LAB_ID'] = LAB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    4. Copy files to your bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://avaus-academy-bucket/instacart/aisles.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/departments.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/order_products__prior.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/order_products__train.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/orders.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/products.csv [Content-Type=application/vnd.ms-excel]...\n",
      "/ [6/6 files][680.3 MiB/680.3 MiB] 100% Done     0.0 B/s                        \n",
      "Operation completed over 6 objects/680.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp gs://avaus-academy-bucket/instacart/*.csv gs://$BUCKET/instacart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    5. Check files are in the bucket you created (not avaus-academy-bucket)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cloud_storage](img/instacart_cloud_storage.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV and put into [bigquery](https://console.cloud.google.com/bigquery?project=avaus-academy&p=avaus-academy&page=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a bigquery client to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a dataset to place the CSV files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Conflict",
     "evalue": "409 POST https://bigquery.googleapis.com/bigquery/v2/projects/avaus-academy/datasets: Already Exists: Dataset avaus-academy:instacart_sebastian_test_4321",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConflict\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b61b06253aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset created!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, dataset, exists_ok, retry)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mapi_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConflict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConflict\u001b[0m: 409 POST https://bigquery.googleapis.com/bigquery/v2/projects/avaus-academy/datasets: Already Exists: Dataset avaus-academy:instacart_sebastian_test_4321"
     ]
    }
   ],
   "source": [
    "# Name of dataset\n",
    "dataset_name = '{PROJECT}.instacart_{NAME}'.format(PROJECT=PROJECT, NAME=LAB_ID)\n",
    "\n",
    "# Create a reference to dataset\n",
    "dataset = bigquery.Dataset(dataset_name)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = client.create_dataset(dataset)\n",
    "print(\"Dataset created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a config to load the CSV files with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True # Autoinfers the schema from the CSV\n",
    "\n",
    "# Files to load\n",
    "files = [\n",
    "    'aisles.csv',\n",
    "    'departments.csv',\n",
    "    'order_products__prior.csv',\n",
    "    'order_products__train.csv',\n",
    "    'orders.csv',\n",
    "    'products.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job for loading aisles.csv with id=ab89af50-5c49-4933-9b0d-888b5690b971\n",
      "Job finished.\n",
      "Loaded 134 rows.\n",
      "\n",
      "Starting job for loading departments.csv with id=4636af0f-fb73-41c1-bd84-4e98f1e3b8b4\n",
      "Job finished.\n",
      "Loaded 21 rows.\n",
      "\n",
      "Starting job for loading order_products__prior.csv with id=4a5fb580-c9df-40f0-aae7-848c8d3d0563\n",
      "Job finished.\n",
      "Loaded 32434489 rows.\n",
      "\n",
      "Starting job for loading order_products__train.csv with id=3c4a0df6-ed08-49df-9f0c-d6349ee1ac66\n",
      "Job finished.\n",
      "Loaded 1384617 rows.\n",
      "\n",
      "Starting job for loading orders.csv with id=794192f3-f5e3-4dce-9931-22447770a241\n",
      "Job finished.\n",
      "Loaded 3421083 rows.\n",
      "\n",
      "Starting job for loading products.csv with id=b7b67170-0064-45fa-a54d-3c3f94fd1941\n",
      "Job finished.\n",
      "Loaded 49688 rows.\n",
      "\n",
      "Finished loading all tables!\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    # Build input path and destination table\n",
    "    input_path = \"gs://{BUCKET}/instacart/{FILE}\".format(BUCKET=BUCKET, FILE=file)\n",
    "    table_name = file.split('.')[0] # Take the name before '.csv' as the name of the table\n",
    "    table = dataset.table(table_name)\n",
    "\n",
    "    # Create a job for loading the CSV to bigquery\n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=input_path, \n",
    "        destination=table, \n",
    "        job_config=job_config\n",
    "    )\n",
    "    print(\"Starting job for loading {FILE} with id={JOB_ID}\".format(FILE=file, JOB_ID=load_job.job_id))\n",
    "\n",
    "    # Waits for table load to complete.\n",
    "    load_job.result()  \n",
    "    print(\"Job finished.\")\n",
    "\n",
    "    # Check stats for the table\n",
    "    destination_table = client.get_table(dataset.table(table_name))\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Finished loading all tables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Check tables are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bigquery](img/instacart_bigquery.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at the table we are going to use: orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3370391</td>\n",
       "      <td>116</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2955606</td>\n",
       "      <td>160</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2735511</td>\n",
       "      <td>177</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356906</td>\n",
       "      <td>186</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1192185</td>\n",
       "      <td>239</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0   3370391      116    prior             1          0                  5   \n",
       "1   2955606      160    prior             1          1                  3   \n",
       "2   2735511      177    prior             1          6                  3   \n",
       "3    356906      186    prior             1          6                  4   \n",
       "4   1192185      239    prior             1          3                  2   \n",
       "\n",
       "  days_since_prior_order  \n",
       "0                   None  \n",
       "1                   None  \n",
       "2                   None  \n",
       "3                   None  \n",
       "4                   None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    LIMIT 5\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Overall stats for table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_orders</th>\n",
       "      <th>nr_customers</th>\n",
       "      <th>min_order_nr</th>\n",
       "      <th>max_order_nr</th>\n",
       "      <th>min_days</th>\n",
       "      <th>max_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3421083</td>\n",
       "      <td>206209</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr_orders  nr_customers  min_order_nr  max_order_nr  min_days  max_days\n",
       "0    3421083        206209             1           100       0.0      30.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) AS nr_orders,\n",
    "        COUNT(DISTINCT user_id) AS nr_customers,\n",
    "        MIN(order_number) AS min_order_nr,\n",
    "        MAX(order_number)  AS max_order_nr,\n",
    "        MIN(days_since_prior_order) AS min_days,\n",
    "        MAX(days_since_prior_order) AS max_days\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~3.5 million orders\n",
    "\n",
    "~200k customers\n",
    "\n",
    "No customer has made more than 100 purchases\n",
    "\n",
    "the column *days_since_prior_order* is censored after 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the different values for *eval_set*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_set</th>\n",
       "      <th>nr_orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prior</td>\n",
       "      <td>3214874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>131209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eval_set  nr_orders\n",
       "0    prior    3214874\n",
       "1    train     131209\n",
       "2     test      75000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        eval_set,\n",
    "        COUNT(*) AS nr_orders\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    GROUP BY \n",
    "        eval_set\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use *prior* for training features and *train* for training targel label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Dig deeper on customer level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>nr_orders</th>\n",
       "      <th>min_order_nr_prior</th>\n",
       "      <th>max_order_nr_prior</th>\n",
       "      <th>min_order_nr_train</th>\n",
       "      <th>max_order_nr_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  nr_orders  min_order_nr_prior  max_order_nr_prior  \\\n",
       "0      116          7                   1                   6   \n",
       "1      160         13                   1                  12   \n",
       "2      239          6                   1                   5   \n",
       "3      294         16                   1                  15   \n",
       "4      313        100                   1                  99   \n",
       "\n",
       "   min_order_nr_train  max_order_nr_train  \n",
       "0                   7                   7  \n",
       "1                  13                  13  \n",
       "2                   6                   6  \n",
       "3                  16                  16  \n",
       "4                 100                 100  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        user_id,\n",
    "        COUNT(*) AS nr_orders,\n",
    "        MIN(CASE WHEN eval_set = 'prior' THEN order_number ELSE NULL END) AS min_order_nr_prior,\n",
    "        MAX(CASE WHEN eval_set = 'prior' THEN order_number ELSE NULL END) AS max_order_nr_prior,\n",
    "        MIN(CASE WHEN eval_set = 'train' THEN order_number ELSE NULL END) AS min_order_nr_train,\n",
    "        MAX(CASE WHEN eval_set = 'train' THEN order_number ELSE NULL END) AS max_order_nr_train    FROM instacart_{LAB_ID}.orders\n",
    "    GROUP BY \n",
    "        user_id\n",
    "    HAVING min_order_nr_train IS NOT NULL\n",
    "    LIMIT 5\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_set = 'prior'* contains all transactions prior to the latest one\n",
    "\n",
    "*eval_set = 'train'* contains the latest transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:\n",
    "Given a user and their latest order, predict how long it will be until the next order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a table with overall features for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.user_features AS\n",
    "    SELECT\n",
    "        user_id,\n",
    "        COUNT(order_id) AS nr_orders,\n",
    "        SUM(days_since_prior_order) AS user_lifetime,\n",
    "        COALESCE(COUNT(order_id) / NULLIF(SUM(days_since_prior_order), 0), 1) AS nr_orders_per_day,\n",
    "        AVG(days_since_prior_order) AS avg_nr_days_between_orders,\n",
    "        COUNT(CASE WHEN order_dow = 0 THEN order_id END) AS nr_orders_saturday,\n",
    "        COUNT(CASE WHEN order_dow = 1 THEN order_id END) AS nr_orders_sunday,\n",
    "        COUNT(CASE WHEN order_dow = 2 THEN order_id END) AS nr_orders_monday,\n",
    "        COUNT(CASE WHEN order_dow = 3 THEN order_id END) AS nr_orders_tuesday,\n",
    "        COUNT(CASE WHEN order_dow = 4 THEN order_id END) AS nr_orders_wednesday,\n",
    "        COUNT(CASE WHEN order_dow = 5 THEN order_id END) AS nr_orders_thursday,\n",
    "        COUNT(CASE WHEN order_dow = 6 THEN order_id END) AS nr_orders_friday,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN order_id END) AS nr_orders_morning,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN order_id END) AS nr_orders_afternoon,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN order_id END) AS nr_orders_evening,\n",
    "        COUNT(CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN order_id END) AS nr_orders_night \n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    WHERE eval_set = 'prior' -- Only use the prior data for training features\n",
    "    GROUP BY\n",
    "        user_id\n",
    "    \"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table\n",
      "Created table\n"
     ]
    }
   ],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.user_features\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(user_features)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a table with features for latest transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_transaction=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.latest_transaction AS\n",
    "    SELECT\n",
    "        user_id,\n",
    "        ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY order_number DESC) AS order_rank,\n",
    "        days_since_prior_order,\n",
    "        CASE WHEN order_dow = 0 THEN 1 ELSE 0 END AS is_saturday_order,\n",
    "        CASE WHEN order_dow = 1 THEN 1 ELSE 0 END AS is_sunday_order,\n",
    "        CASE WHEN order_dow = 2 THEN 1 ELSE 0 END AS is_monday_order,\n",
    "        CASE WHEN order_dow = 3 THEN 1 ELSE 0 END AS is_tuesday_order,\n",
    "        CASE WHEN order_dow = 4 THEN 1 ELSE 0 END AS is_wednesday_order,\n",
    "        CASE WHEN order_dow = 5 THEN 1 ELSE 0 END AS is_thursday_order,\n",
    "        CASE WHEN order_dow = 6 THEN 1 ELSE 0 END AS is_friday_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN 1 ELSE 0 END AS is_morning_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN 1 ELSE 0 END AS is_afternoon_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN 1 ELSE 0 END AS is_evening_order,\n",
    "        CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN 1 ELSE 0 END AS is_night_order\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    WHERE eval_set = 'prior'\n",
    "\"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table\n",
      "Created table\n"
     ]
    }
   ],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.latest_transaction\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(latest_transaction)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a table with features and target label used for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.feature_set AS\n",
    "    SELECT\n",
    "        -- Observation key\n",
    "        lt.user_id,\n",
    "        \n",
    "        -- Features about last order\n",
    "        lt.is_saturday_order,\n",
    "        lt.is_sunday_order,\n",
    "        lt.is_monday_order,\n",
    "        lt.is_tuesday_order,\n",
    "        lt.is_wednesday_order,\n",
    "        lt.is_thursday_order,\n",
    "        lt.is_friday_order,\n",
    "        lt.is_morning_order,\n",
    "        lt.is_afternoon_order,\n",
    "        lt.is_evening_order,\n",
    "        lt.is_night_order,\n",
    "        lt.days_since_prior_order,\n",
    "        \n",
    "        -- Features about user\n",
    "        uf.nr_orders,\n",
    "        uf.user_lifetime,\n",
    "        uf.nr_orders_per_day,\n",
    "        uf.avg_nr_days_between_orders,\n",
    "        uf.nr_orders_saturday,\n",
    "        uf.nr_orders_sunday,\n",
    "        uf.nr_orders_monday,\n",
    "        uf.nr_orders_tuesday,\n",
    "        uf.nr_orders_wednesday,\n",
    "        uf.nr_orders_thursday,\n",
    "        uf.nr_orders_friday,\n",
    "        uf.nr_orders_morning,\n",
    "        uf.nr_orders_afternoon,\n",
    "        uf.nr_orders_evening,\n",
    "        uf.nr_orders_night,\n",
    "        \n",
    "        -- Target label\n",
    "        target.days_since_prior_order AS days_to_next_order,\n",
    "        \n",
    "        -- Train vs test\n",
    "        RAND() <= 0.8 AS is_train\n",
    "    FROM instacart_{LAB_ID}.latest_transaction lt\n",
    "    INNER JOIN instacart_{LAB_ID}.user_features uf ON uf.user_id = lt.user_id\n",
    "    INNER JOIN instacart_{LAB_ID}.orders target ON target.user_id = lt.user_id \n",
    "        AND target.eval_set = 'train' \n",
    "    WHERE lt.order_rank = 1 -- Take last transaction in prior set\n",
    "\"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table\n",
      "Created table\n"
     ]
    }
   ],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.feature_set\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(feature_set)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check tables are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bigquery](img/instacart_bigquery.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the training data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.feature_set\n",
    "    WHERE is_train\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create training dataset for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Some variables\n",
    "drop_columns = ['user_id']  # Columns not to include in training\n",
    "target_label = 'days_to_next_order'\n",
    "\n",
    "# Create dataset\n",
    "features = df.drop(drop_columns + [target_label], axis=1)\n",
    "labels = df[target_label]\n",
    "dtrain = xgb.DMatrix(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "bst = xgb.train({'silent': 1}, dtrain, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save the model to the disk on this jupyterlab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from google.cloud import storage\n",
    "model_name = 'model.bst'\n",
    "bst.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a folder in Google Cloud Storage to upload the model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for the model in GCS\n",
    "storage_client = storage.Client(project=PROJECT)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET)\n",
    "\n",
    "folder = bucket.blob('instacart/model/')\n",
    "folder.upload_from_string('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Upload the model to [Google Cloud Storage](https://console.cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model to GCS\n",
    "blob = bucket.blob('instacart/model/{MODEL_NAME}'.format(MODEL_NAME=model_name))\n",
    "blob.upload_from_filename(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_model.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some variables needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"gs://{BUCKET}/instacart/model\".format(BUCKET=BUCKET)\n",
    "MODEL_NAME = \"xgboost_model_{LAB_ID}\".format(LAB_ID=LAB_ID)\n",
    "VERSION = \"v1_0_0\"\n",
    "FRAMEWORK = \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MODEL_PATH'] = MODEL_PATH\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['VERSION'] = VERSION\n",
    "os.environ['FRAMEWORK'] = FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a model and a version of the model in AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-09-30T11:22:59Z'\n",
      "deploymentUri: gs://sebastian-test-4321/instacart/model\n",
      "etag: MfBWs1aE4sU=\n",
      "framework: XGBOOST\n",
      "isDefault: true\n",
      "machineType: mls1-c1-m2\n",
      "name: projects/avaus-academy/models/xgboost_model_sebastian_test_4321/versions/v1_0_0\n",
      "pythonVersion: '3.5'\n",
      "runtimeVersion: '1.14'\n",
      "state: READY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/avaus-academy/models/xgboost_model_sebastian_test_4321].\n",
      "Creating version (this might take a few minutes)......\n",
      ".........................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Create placeholder for model\n",
    "gcloud ai-platform models create $MODEL_NAME --regions $REGION\n",
    "\n",
    "# Create a version of the model\n",
    "gcloud ai-platform versions create $VERSION \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin $MODEL_PATH \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --framework $FRAMEWORK \\\n",
    "  --python-version=3.5\n",
    "\n",
    "# Check model\n",
    "gcloud ai-platform versions describe $VERSION \\\n",
    "  --model $MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check models in AI platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_ai_platform.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [10.614230155944824, 23.52460479736328]}'\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Get an access token\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "\n",
    "# Construct the API url\n",
    "api = \"https://ml.googleapis.com/v1/projects/{PROJECT}/models/{MODEL_NAME}/versions/{VERSION}:predict\"\\\n",
    "    .format(PROJECT=PROJECT, MODEL_NAME=MODEL_NAME, VERSION=VERSION)\n",
    "\n",
    "# Header and data field of HTTP request\n",
    "headers = {'Authorization': 'Bearer ' + token }\n",
    "data = {\n",
    "  'instances': [\n",
    "      # True value of target label \"days_to_next_order\": 8.0\n",
    "      [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 8.0, 20, 126.0, 0.15873015873015872, 6.631578947368422, 2, 1, 1, 2, 6, 3, 5, 6, 14, 0, 0],\n",
    "      \n",
    "      # True value of target label \"days_to_next_order\": 18.0\n",
    "      [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 30.0, 3, 60.0, 0.05, 30.0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Call the API\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up what we just did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Delete the version of the model and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This will delete version [v1_0_0]...\n",
      "\n",
      "Do you want to continue (Y/n)?  Please enter 'y' or 'n':  \n",
      "Deleting version [v1_0_0]......\n",
      "..................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform versions delete $VERSION --model=$MODEL_NAME\n",
    "gcloud ai-platform models delete $MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Delete the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = client.delete_dataset(dataset, delete_contents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Delete bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://sebastian-test-4321/instacart/#1569841969737661...\n",
      "Removing gs://sebastian-test-4321/instacart/aisles.csv#1569841986212126...      \n",
      "Removing gs://sebastian-test-4321/instacart/departments.csv#1569841986182189... \n",
      "Removing gs://sebastian-test-4321/instacart/model/#1569842562472200...          \n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://sebastian-test-4321/instacart/model/model.bst#1569842562782272...\n",
      "Removing gs://sebastian-test-4321/instacart/order_products__prior.csv#1569842013043583...\n",
      "Removing gs://sebastian-test-4321/instacart/order_products__train.csv#1569841986569047...\n",
      "Removing gs://sebastian-test-4321/instacart/orders.csv#1569841999973779...      \n",
      "Removing gs://sebastian-test-4321/instacart/products.csv#1569841987087989...    \n",
      "/ [9 objects]                                                                   \n",
      "Operation completed over 9 objects.                                              \n",
      "Removing gs://sebastian-test-4321/...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil rm -r gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Shutdown this jupyterlab instance "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
