{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost==0.81 pandas==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-api-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data in google cloud storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    1. Create a bucket in <a href=\"https://console.cloud.google.com/storage/\">cloud storage</a> to store the raw data in. Remember the name of the bucket.\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    2. Create a folder named 'instacart' in the bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    3. Download the <a href=https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz>instacart</a> dataset, unzip it and upload each csv file to the folder created above\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cloud_storage](img/instacart_cloud_storage.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some configs we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'avaus-academy-bucket' # The name of the bucket created above\n",
    "PROJECT = 'avaus-academy' # Your project name here\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV and put into bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bigquery client to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset to place the CSV files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'instacart'\n",
    "dataset_ref = bigquery.dataset.DatasetReference(project=PROJECT, dataset_id=dataset_name)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "\n",
    "#client.delete_dataset(dataset, delete_contents=True)\n",
    "dataset = client.create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a config to load the CSV files with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True\n",
    "files = [\n",
    "    'aisles.csv',\n",
    "    'departments.csv',\n",
    "    'order_products__prior.csv',\n",
    "    'order_products__train.csv',\n",
    "    'orders.csv',\n",
    "    'products.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # Build input path and destination table\n",
    "    input_path = \"gs://{BUCKET}/instacart/{FILE}\".format(BUCKET=BUCKET, FILE=file)\n",
    "    table_name = file.split('.')[0] # Take the name before '.csv' as the name of the table\n",
    "    table = dataset.table(table_name)\n",
    "\n",
    "    # Create a job for loading \n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=input_path, \n",
    "        destination=table, \n",
    "        job_config=job_config\n",
    "    )\n",
    "    print(\"Starting job for loading {FILE} with id={JOB_ID}\".format(FILE=file, JOB_ID=load_job.job_id))\n",
    "\n",
    "    load_job.result()  # Waits for table load to complete.\n",
    "    print(\"Job finished.\")\n",
    "\n",
    "    destination_table = client.get_table(dataset_ref.table(table_name))\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Finished loading all tables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bigquery](img/instacart_bigquery.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Given a user and their \"latest\" order, predict how long it will be until the next order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "    CREATE TABLE instacart.feature_set AS\n",
    "    WITH \n",
    "    user_features AS (\n",
    "        SELECT\n",
    "            user_id,\n",
    "            COUNT(order_id) AS nr_orders,\n",
    "            SUM(days_since_prior_order) AS user_lifetime,\n",
    "            COALESCE(COUNT(order_id) / NULLIF(SUM(days_since_prior_order), 0), 1) AS nr_orders_per_day,\n",
    "            AVG(days_since_prior_order) AS avg_nr_days_between_orders,\n",
    "            COUNT(CASE WHEN order_dow = 0 THEN order_id END) AS nr_orders_saturday,\n",
    "            COUNT(CASE WHEN order_dow = 1 THEN order_id END) AS nr_orders_sunday,\n",
    "            COUNT(CASE WHEN order_dow = 2 THEN order_id END) AS nr_orders_monday,\n",
    "            COUNT(CASE WHEN order_dow = 3 THEN order_id END) AS nr_orders_tuesday,\n",
    "            COUNT(CASE WHEN order_dow = 4 THEN order_id END) AS nr_orders_wednesday,\n",
    "            COUNT(CASE WHEN order_dow = 5 THEN order_id END) AS nr_orders_thursday,\n",
    "            COUNT(CASE WHEN order_dow = 6 THEN order_id END) AS nr_orders_friday,\n",
    "            COUNT(CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN order_id END) AS nr_orders_morning,\n",
    "            COUNT(CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN order_id END) AS nr_orders_afternoon,\n",
    "            COUNT(CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN order_id END) AS nr_orders_evening,\n",
    "            COUNT(CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN order_id END) AS nr_orders_night \n",
    "        FROM instacart.orders\n",
    "        WHERE eval_set = 'prior'\n",
    "        GROUP BY\n",
    "            user_id\n",
    "    ),\n",
    "    last_tx AS (\n",
    "        SELECT\n",
    "            user_id,\n",
    "            eval_set,\n",
    "            CASE WHEN order_dow = 0 THEN 1 ELSE 0 END AS is_saturday_order,\n",
    "            CASE WHEN order_dow = 1 THEN 1 ELSE 0 END AS is_sunday_order,\n",
    "            CASE WHEN order_dow = 2 THEN 1 ELSE 0 END AS is_monday_order,\n",
    "            CASE WHEN order_dow = 3 THEN 1 ELSE 0 END AS is_tuesday_order,\n",
    "            CASE WHEN order_dow = 4 THEN 1 ELSE 0 END AS is_wednesday_order,\n",
    "            CASE WHEN order_dow = 5 THEN 1 ELSE 0 END AS is_thursday_order,\n",
    "            CASE WHEN order_dow = 6 THEN 1 ELSE 0 END AS is_friday_order,\n",
    "            CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN 1 ELSE 0 END AS is_morning_order,\n",
    "            CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN 1 ELSE 0 END AS is_afternoon_order,\n",
    "            CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN 1 ELSE 0 END AS is_evening_order,\n",
    "            CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN 1 ELSE 0 END AS is_night_order,\n",
    "            days_since_prior_order,\n",
    "            ROW_NUMBER() OVER(PARTITION BY user_id, eval_set ORDER BY order_number DESC) AS order_rank\n",
    "        FROM instacart.orders\n",
    "    )\n",
    "    SELECT\n",
    "        -- Observation key\n",
    "        lt.user_id,\n",
    "        \n",
    "        -- Features about last order\n",
    "        lt.is_saturday_order,\n",
    "        lt.is_sunday_order,\n",
    "        lt.is_monday_order,\n",
    "        lt.is_tuesday_order,\n",
    "        lt.is_wednesday_order,\n",
    "        lt.is_thursday_order,\n",
    "        lt.is_friday_order,\n",
    "        lt.is_morning_order,\n",
    "        lt.is_afternoon_order,\n",
    "        lt.is_evening_order,\n",
    "        lt.is_night_order,\n",
    "        lt.days_since_prior_order,\n",
    "        \n",
    "        -- Features about user\n",
    "        uf.nr_orders,\n",
    "        uf.user_lifetime,\n",
    "        uf.nr_orders_per_day,\n",
    "        uf.avg_nr_days_between_orders,\n",
    "        uf.nr_orders_saturday,\n",
    "        uf.nr_orders_sunday,\n",
    "        uf.nr_orders_monday,\n",
    "        uf.nr_orders_tuesday,\n",
    "        uf.nr_orders_wednesday,\n",
    "        uf.nr_orders_thursday,\n",
    "        uf.nr_orders_friday,\n",
    "        uf.nr_orders_morning,\n",
    "        uf.nr_orders_afternoon,\n",
    "        uf.nr_orders_evening,\n",
    "        uf.nr_orders_night,\n",
    "        \n",
    "        -- Target label\n",
    "        target.days_since_prior_order AS days_to_next_order,\n",
    "        \n",
    "        -- Train vs test\n",
    "        RAND() <= 0.8 AS is_train\n",
    "    FROM last_tx lt\n",
    "    INNER JOIN user_features uf ON uf.user_id = lt.user_id\n",
    "    INNER JOIN last_tx target ON target.user_id = lt.user_id AND target.eval_set = 'train' \n",
    "    WHERE lt.eval_set = 'prior' AND lt.order_rank = 1 -- Take last transaction in prior set\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart.feature_set\")\n",
    "query_drop.result()\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(query)\n",
    "results = query_create.result()\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![feature_set](img/instacart_feature_set.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "drop_features = ['user_id']\n",
    "target_label = 'days_to_next_order'\n",
    "train_sql = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM instacart.feature_set\n",
    "WHERE is_train\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "client = bigquery.Client(project=PROJECT)\n",
    "df = client.query(train_sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "import xgboost as xgb\n",
    "features = df.drop(drop_features + [target_label], axis=1)\n",
    "labels = df[target_label]\n",
    "dtrain = xgb.DMatrix(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:57] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:57] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:57] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:58] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 86 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13:37:59] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "bst = xgb.train({}, dtrain, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from google.cloud import storage\n",
    "model_name = 'model.bst'\n",
    "bst.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for the model in GCS\n",
    "storage_client = storage.Client(project=PROJECT)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET)\n",
    "\n",
    "folder = bucket.blob('instacart/model/')\n",
    "folder.upload_from_string('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model to GCS\n",
    "blob = bucket.blob('instacart/model/{MODEL_NAME}'.format(MODEL_NAME=model_name))\n",
    "blob.upload_from_filename(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_model.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-09-16T13:42:35Z'\n",
      "deploymentUri: gs://avaus-academy-bucket/instacart/model\n",
      "etag: _frc7oW9h0k=\n",
      "framework: XGBOOST\n",
      "isDefault: true\n",
      "machineType: mls1-c1-m2\n",
      "name: projects/avaus-academy/models/xgboost_model/versions/xgboost_model_v1_0_0\n",
      "pythonVersion: '3.5'\n",
      "runtimeVersion: '1.14'\n",
      "state: READY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ai-platform.models.create) Resource in project [avaus-academy] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "ERROR: (gcloud.ai-platform.versions.create) ALREADY_EXISTS: Field: version.name Error: A version with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A version with the same name already exists.\n",
      "    field: version.name\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Variables\n",
    "MODEL_PATH=\"gs://$BUCKET/instacart/model\"\n",
    "VERSION_NAME=\"xgboost_model_v1_0_0\"\n",
    "MODEL_NAME=\"xgboost_model\"\n",
    "FRAMEWORK=\"xgboost\"\n",
    "\n",
    "# Create placeholder for model\n",
    "gcloud ai-platform models create $MODEL_NAME --regions $REGION\n",
    "\n",
    "# Create a version of the model\n",
    "gcloud ai-platform versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin $MODEL_PATH \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --framework $FRAMEWORK \\\n",
    "  --python-version=3.5\n",
    "\n",
    "# Check model\n",
    "gcloud ai-platform versions describe $VERSION_NAME \\\n",
    "  --model $MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_ai_platform.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [9.828922271728516, 24.23944854736328]}'\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_NAME = 'xgboost_model'\n",
    "MODEL_VERSION = 'xgboost_model_v1_0_0'\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = \"https://ml.googleapis.com/v1/projects/{PROJECT}/models/{MODEL_NAME}/versions/{MODEL_VERSION}:predict\"\\\n",
    "    .format(PROJECT=PROJECT, MODEL_NAME=MODEL_NAME, MODEL_VERSION=MODEL_VERSION)\n",
    "\n",
    "headers = {'Authorization': 'Bearer ' + token }\n",
    "data = {\n",
    "  'instances': [\n",
    "      # \"days_to_next_order\": 8.0\n",
    "      [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 8.0, 20, 126.0, 0.15873015873015872, 6.631578947368422, 2, 1, 1, 2, 6, 3, 5, 6, 14, 0, 0],\n",
    "      \n",
    "      # \"days_to_next_order\": 18.0\n",
    "      [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 30.0, 3, 60.0, 0.05, 30.0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
    "  ]\n",
    "}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
