{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost==0.81 pandas==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-api-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dropdown menu in top left, select:\n",
    "\n",
    "    Kernel --> Restart Kernel and Clear All Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data into [Google Cloud Storage](https://console.cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    1. Create a bucket in <a href=\"https://console.cloud.google.com/storage/\">cloud storage</a> to store the raw data in. Use no weird characters in the name. Remember the name of the bucket.\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    2. Create a folder named 'instacart' in the bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    3. Set parameters\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'instacart-sebastian-test' # The name of the bucket created above\n",
    "PROJECT = 'avaus-academy' # Do not change\n",
    "REGION = 'europe-west1' # Do not change\n",
    "LAB_ID = BUCKET.replace('-', '_').replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['LAB_ID'] = LAB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    4. Copy files to your bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -m cp gs://avaus-academy-bucket/instacart/*.csv gs://$BUCKET/instacart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    5. Check files are in the bucket you created (not avaus-academy-bucket)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cloud_storage](img/instacart_cloud_storage.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV and put into [bigquery](https://console.cloud.google.com/bigquery?project=avaus-academy&p=avaus-academy&page=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a bigquery client to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a dataset to place the CSV files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of dataset\n",
    "dataset_name = '{PROJECT}.instacart_{NAME}'.format(PROJECT=PROJECT, NAME=LAB_ID)\n",
    "\n",
    "# Create a reference to dataset\n",
    "dataset = bigquery.Dataset(dataset_name)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = client.create_dataset(dataset)\n",
    "print(\"Dataset created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a config to load the CSV files with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True # Autoinfers the schema from the CSV\n",
    "\n",
    "# Files to load\n",
    "files = [\n",
    "    'aisles.csv',\n",
    "    'departments.csv',\n",
    "    'order_products__prior.csv',\n",
    "    'order_products__train.csv',\n",
    "    'orders.csv',\n",
    "    'products.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # Build input path and destination table\n",
    "    input_path = \"gs://{BUCKET}/instacart/{FILE}\".format(BUCKET=BUCKET, FILE=file)\n",
    "    table_name = file.split('.')[0] # Take the name before '.csv' as the name of the table\n",
    "    table = dataset.table(table_name)\n",
    "\n",
    "    # Create a job for loading the CSV to bigquery\n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=input_path, \n",
    "        destination=table, \n",
    "        job_config=job_config\n",
    "    )\n",
    "    print(\"Starting job for loading {FILE} with id={JOB_ID}\".format(FILE=file, JOB_ID=load_job.job_id))\n",
    "\n",
    "    # Waits for table load to complete.\n",
    "    load_job.result()  \n",
    "    print(\"Job finished.\")\n",
    "\n",
    "    # Check stats for the table\n",
    "    destination_table = client.get_table(dataset.table(table_name))\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Finished loading all tables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Check tables are there in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at the table we are going to use: orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    LIMIT 5\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Overall stats for table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) AS nr_orders,\n",
    "        COUNT(DISTINCT user_id) AS nr_customers,\n",
    "        MIN(order_number) AS min_order_nr,\n",
    "        MAX(order_number)  AS max_order_nr,\n",
    "        MIN(days_since_prior_order) AS min_days,\n",
    "        MAX(days_since_prior_order) AS max_days\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~3.5 million orders\n",
    "\n",
    "~200k customers\n",
    "\n",
    "No customer has made more than 100 purchases\n",
    "\n",
    "the column *days_since_prior_order* is censored after 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the different values for *eval_set*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        eval_set,\n",
    "        COUNT(*) AS nr_orders\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    GROUP BY \n",
    "        eval_set\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use *prior* for training features and *train* for training targel label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Dig deeper on customer level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        user_id,\n",
    "        COUNT(*) AS nr_orders,\n",
    "        MIN(CASE WHEN eval_set = 'prior' THEN order_number ELSE NULL END) AS min_order_nr_prior,\n",
    "        MAX(CASE WHEN eval_set = 'prior' THEN order_number ELSE NULL END) AS max_order_nr_prior,\n",
    "        MIN(CASE WHEN eval_set = 'train' THEN order_number ELSE NULL END) AS min_order_nr_train,\n",
    "        MAX(CASE WHEN eval_set = 'train' THEN order_number ELSE NULL END) AS max_order_nr_train    FROM instacart_{LAB_ID}.orders\n",
    "    GROUP BY \n",
    "        user_id\n",
    "    HAVING min_order_nr_train IS NOT NULL\n",
    "    LIMIT 5\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_set = 'prior'* contains all transactions prior to the latest one\n",
    "\n",
    "*eval_set = 'train'* contains the latest transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:\n",
    "Given a user and their latest order, predict how long it will be until the next order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a table with overall features for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.user_features AS\n",
    "    SELECT\n",
    "        user_id,\n",
    "        COUNT(order_id) AS nr_orders,\n",
    "        SUM(days_since_prior_order) AS user_lifetime,\n",
    "        COALESCE(COUNT(order_id) / NULLIF(SUM(days_since_prior_order), 0), 1) AS nr_orders_per_day,\n",
    "        AVG(days_since_prior_order) AS avg_nr_days_between_orders,\n",
    "        COUNT(CASE WHEN order_dow = 0 THEN order_id END) AS nr_orders_saturday,\n",
    "        COUNT(CASE WHEN order_dow = 1 THEN order_id END) AS nr_orders_sunday,\n",
    "        COUNT(CASE WHEN order_dow = 2 THEN order_id END) AS nr_orders_monday,\n",
    "        COUNT(CASE WHEN order_dow = 3 THEN order_id END) AS nr_orders_tuesday,\n",
    "        COUNT(CASE WHEN order_dow = 4 THEN order_id END) AS nr_orders_wednesday,\n",
    "        COUNT(CASE WHEN order_dow = 5 THEN order_id END) AS nr_orders_thursday,\n",
    "        COUNT(CASE WHEN order_dow = 6 THEN order_id END) AS nr_orders_friday,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN order_id END) AS nr_orders_morning,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN order_id END) AS nr_orders_afternoon,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN order_id END) AS nr_orders_evening,\n",
    "        COUNT(CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN order_id END) AS nr_orders_night \n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    WHERE eval_set = 'prior' -- Only use the prior data for training features\n",
    "    GROUP BY\n",
    "        user_id\n",
    "    \"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.user_features\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(user_features)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a table with features for latest transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_transaction=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.latest_transaction AS\n",
    "    SELECT\n",
    "        user_id,\n",
    "        ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY order_number DESC) AS order_rank,\n",
    "        days_since_prior_order,\n",
    "        CASE WHEN order_dow = 0 THEN 1 ELSE 0 END AS is_saturday_order,\n",
    "        CASE WHEN order_dow = 1 THEN 1 ELSE 0 END AS is_sunday_order,\n",
    "        CASE WHEN order_dow = 2 THEN 1 ELSE 0 END AS is_monday_order,\n",
    "        CASE WHEN order_dow = 3 THEN 1 ELSE 0 END AS is_tuesday_order,\n",
    "        CASE WHEN order_dow = 4 THEN 1 ELSE 0 END AS is_wednesday_order,\n",
    "        CASE WHEN order_dow = 5 THEN 1 ELSE 0 END AS is_thursday_order,\n",
    "        CASE WHEN order_dow = 6 THEN 1 ELSE 0 END AS is_friday_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN 1 ELSE 0 END AS is_morning_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN 1 ELSE 0 END AS is_afternoon_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN 1 ELSE 0 END AS is_evening_order,\n",
    "        CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN 1 ELSE 0 END AS is_night_order\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    WHERE eval_set = 'prior'\n",
    "\"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.latest_transaction\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(latest_transaction)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a table with features and target label used for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.feature_set AS\n",
    "    SELECT\n",
    "        -- Observation key\n",
    "        lt.user_id,\n",
    "        \n",
    "        -- Features about last order\n",
    "        lt.is_saturday_order,\n",
    "        lt.is_sunday_order,\n",
    "        lt.is_monday_order,\n",
    "        lt.is_tuesday_order,\n",
    "        lt.is_wednesday_order,\n",
    "        lt.is_thursday_order,\n",
    "        lt.is_friday_order,\n",
    "        lt.is_morning_order,\n",
    "        lt.is_afternoon_order,\n",
    "        lt.is_evening_order,\n",
    "        lt.is_night_order,\n",
    "        lt.days_since_prior_order,\n",
    "        \n",
    "        -- Features about user\n",
    "        uf.nr_orders,\n",
    "        uf.user_lifetime,\n",
    "        uf.nr_orders_per_day,\n",
    "        uf.avg_nr_days_between_orders,\n",
    "        uf.nr_orders_saturday,\n",
    "        uf.nr_orders_sunday,\n",
    "        uf.nr_orders_monday,\n",
    "        uf.nr_orders_tuesday,\n",
    "        uf.nr_orders_wednesday,\n",
    "        uf.nr_orders_thursday,\n",
    "        uf.nr_orders_friday,\n",
    "        uf.nr_orders_morning,\n",
    "        uf.nr_orders_afternoon,\n",
    "        uf.nr_orders_evening,\n",
    "        uf.nr_orders_night,\n",
    "        \n",
    "        -- Target label\n",
    "        target.days_since_prior_order AS days_to_next_order,\n",
    "        \n",
    "        -- Train vs test\n",
    "        RAND() <= 0.8 AS is_train\n",
    "    FROM instacart_{LAB_ID}.latest_transaction lt\n",
    "    INNER JOIN instacart_{LAB_ID}.user_features uf ON uf.user_id = lt.user_id\n",
    "    INNER JOIN instacart_{LAB_ID}.orders target ON target.user_id = lt.user_id \n",
    "        AND target.eval_set = 'train' \n",
    "    WHERE lt.order_rank = 1 -- Take last transaction in prior set\n",
    "\"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.feature_set\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(feature_set)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check tables are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bigquery](img/instacart_bigquery.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the training data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.feature_set\n",
    "    WHERE is_train\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create training dataset for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Some variables\n",
    "drop_columns = ['user_id']  # Columns not to include in training\n",
    "target_label = 'days_to_next_order'\n",
    "\n",
    "# Create dataset\n",
    "features = df.drop(drop_columns + [target_label], axis=1)\n",
    "labels = df[target_label]\n",
    "dtrain = xgb.DMatrix(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "bst = xgb.train({'silent': 1}, dtrain, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save the model to the disk on this jupyterlab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from google.cloud import storage\n",
    "model_name = 'model.bst'\n",
    "bst.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a folder in Google Cloud Storage to upload the model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for the model in GCS\n",
    "storage_client = storage.Client(project=PROJECT)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET)\n",
    "\n",
    "folder = bucket.blob('instacart/model/')\n",
    "folder.upload_from_string('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Upload the model to [Google Cloud Storage](https://console.cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model to GCS\n",
    "blob = bucket.blob('instacart/model/{MODEL_NAME}'.format(MODEL_NAME=model_name))\n",
    "blob.upload_from_filename(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_model.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some variables needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"gs://{BUCKET}/instacart/model\".format(BUCKET=BUCKET)\n",
    "MODEL_NAME = \"xgboost_model_{LAB_ID}\".format(LAB_ID=LAB_ID)\n",
    "VERSION = \"v1_0_0\"\n",
    "FRAMEWORK = \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MODEL_PATH'] = MODEL_PATH\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['VERSION'] = VERSION\n",
    "os.environ['FRAMEWORK'] = FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a model and a version of the model in AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Create placeholder for model\n",
    "gcloud ai-platform models create $MODEL_NAME --region=$REGION\n",
    "\n",
    "# Create a version of the model\n",
    "gcloud ai-platform versions create $VERSION \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin $MODEL_PATH \\\n",
    "  --region $REGION \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --framework $FRAMEWORK \\\n",
    "  --python-version=3.5\n",
    "\n",
    "# Check model\n",
    "gcloud ai-platform versions describe $VERSION \\\n",
    "  --model $MODEL_NAME --region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check models in AI platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_ai_platform.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "creds, project = google.auth.default()\n",
    "\n",
    "# creds.valid is False, and creds.token is None\n",
    "# Need to refresh credentials to populate those\n",
    "\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "token = creds.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# Construct the API url\n",
    "api = \"https://{REGION}-ml.googleapis.com/v1/projects/{PROJECT}/models/{MODEL_NAME}/versions/{VERSION}:predict\"\\\n",
    "    .format(REGION=REGION, PROJECT=PROJECT, MODEL_NAME=MODEL_NAME, VERSION=VERSION)\n",
    "print(api)\n",
    "# Header and data field of HTTP request\n",
    "headers = {'Authorization': 'Bearer ' + token }\n",
    "data = {\n",
    "  'instances': [\n",
    "      # True value of target label \"days_to_next_order\": 8.0\n",
    "      [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 8.0, 20, 126.0, 0.15873015873015872, 6.631578947368422, 2, 1, 1, 2, 6, 3, 5, 6, 14, 0, 0],\n",
    "      \n",
    "      # True value of target label \"days_to_next_order\": 18.0\n",
    "      [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 30.0, 3, 60.0, 0.05, 30.0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Call the API\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up what we just did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Delete the version of the model and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ai-platform versions delete $VERSION --model=$MODEL_NAME --region=$REGION\n",
    "gcloud ai-platform models delete $MODEL_NAME --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Delete the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = client.delete_dataset(dataset, delete_contents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Delete bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil rm -r gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Shutdown this jupyterlab instance "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
