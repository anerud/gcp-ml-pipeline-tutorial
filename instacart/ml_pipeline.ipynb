{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-api-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dropdown menu in top left, select:\n",
    "\n",
    "    Kernel --> Restart Kernel and Clear All Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test installed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data into [Google Cloud Storage](https://console.cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    1. Create a bucket in <a href=\"https://console.cloud.google.com/storage/\">cloud storage</a> to store the raw data in. Use no weird characters in the name. Remember the name of the bucket.\n",
    "    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    2. Create a folder named 'instacart' in the bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    3. Set parameters\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'instacart-sebastian-test' # The name of the bucket created above\n",
    "REGION = 'europe-west1' # Your region of choice\n",
    "PROJECT = 'avaus-academy' # Do not change\n",
    "LAB_ID = BUCKET.replace('-', '_').replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['LAB_ID'] = LAB_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    4. Copy files to your bucket\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://avaus-academy-bucket/instacart/order_products__prior.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/departments.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/aisles.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/order_products__train.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/orders.csv [Content-Type=application/vnd.ms-excel]...\n",
      "Copying gs://avaus-academy-bucket/instacart/products.csv [Content-Type=application/vnd.ms-excel]...\n",
      "/ [6/6 files][680.3 MiB/680.3 MiB] 100% Done                                    \n",
      "Operation completed over 6 objects/680.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp gs://avaus-academy-bucket/instacart/*.csv gs://$BUCKET/instacart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "    5. Check files are in the bucket you created (not avaus-academy-bucket)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cloud_storage](img/instacart_cloud_storage.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV and put into [bigquery](https://console.cloud.google.com/bigquery?project=avaus-academy&p=avaus-academy&page=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a bigquery client to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a dataset to place the CSV files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Conflict",
     "evalue": "409 POST https://bigquery.googleapis.com/bigquery/v2/projects/avaus-academy/datasets?prettyPrint=false: Already Exists: Dataset avaus-academy:instacart_instacart_sebastian_test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConflict\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b61b06253aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset created!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, dataset, exists_ok, retry, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             )\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             ):\n\u001b[0;32m--> 747\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             )\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConflict\u001b[0m: 409 POST https://bigquery.googleapis.com/bigquery/v2/projects/avaus-academy/datasets?prettyPrint=false: Already Exists: Dataset avaus-academy:instacart_instacart_sebastian_test"
     ]
    }
   ],
   "source": [
    "# Name of dataset\n",
    "dataset_name = '{PROJECT}.instacart_{NAME}'.format(PROJECT=PROJECT, NAME=LAB_ID)\n",
    "\n",
    "# Create a reference to dataset\n",
    "dataset = bigquery.Dataset(dataset_name)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = client.create_dataset(dataset)\n",
    "print(\"Dataset created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a config to load the CSV files with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True # Autoinfers the schema from the CSV\n",
    "\n",
    "# Files to load\n",
    "files = [\n",
    "    'aisles.csv',\n",
    "    'departments.csv',\n",
    "    'order_products__prior.csv',\n",
    "    'order_products__train.csv',\n",
    "    'orders.csv',\n",
    "    'products.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # Build input path and destination table\n",
    "    input_path = \"gs://{BUCKET}/instacart/{FILE}\".format(BUCKET=BUCKET, FILE=file)\n",
    "    table_name = file.split('.')[0] # Take the name before '.csv' as the name of the table\n",
    "    table = dataset.table(table_name)\n",
    "\n",
    "    # Create a job for loading the CSV to bigquery\n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=input_path, \n",
    "        destination=table, \n",
    "        job_config=job_config\n",
    "    )\n",
    "    print(\"Starting job for loading {FILE} with id={JOB_ID}\".format(FILE=file, JOB_ID=load_job.job_id))\n",
    "\n",
    "    # Waits for table load to complete.\n",
    "    load_job.result()  \n",
    "    print(\"Job finished.\")\n",
    "\n",
    "    # Check stats for the table\n",
    "    destination_table = client.get_table(dataset.table(table_name))\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Finished loading all tables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Check tables are there in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at the table we are going to use: orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    LIMIT 5\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Overall stats for table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) AS nr_orders,\n",
    "        COUNT(DISTINCT user_id) AS nr_customers,\n",
    "        MIN(order_number) AS min_order_nr,\n",
    "        MAX(order_number)  AS max_order_nr,\n",
    "        MIN(days_since_prior_order) AS min_days,\n",
    "        MAX(days_since_prior_order) AS max_days\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~3.5 million orders\n",
    "\n",
    "~200k customers\n",
    "\n",
    "No customer has made more than 100 purchases\n",
    "\n",
    "the column *days_since_prior_order* is censored after 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the different values for *eval_set*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        eval_set,\n",
    "        COUNT(*) AS nr_orders\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    GROUP BY \n",
    "        eval_set\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use *prior* for training features and *train* for training targel label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Dig deeper on customer level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        user_id,\n",
    "        COUNT(*) AS nr_orders,\n",
    "        MIN(CASE WHEN eval_set = 'prior' THEN order_number ELSE NULL END) AS min_order_nr_prior,\n",
    "        MAX(CASE WHEN eval_set = 'prior' THEN order_number ELSE NULL END) AS max_order_nr_prior,\n",
    "        MIN(CASE WHEN eval_set = 'train' THEN order_number ELSE NULL END) AS min_order_nr_train,\n",
    "        MAX(CASE WHEN eval_set = 'train' THEN order_number ELSE NULL END) AS max_order_nr_train    FROM instacart_{LAB_ID}.orders\n",
    "    GROUP BY \n",
    "        user_id\n",
    "    HAVING min_order_nr_train IS NOT NULL\n",
    "    LIMIT 5\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*eval_set = 'prior'* contains all transactions prior to the latest one\n",
    "\n",
    "*eval_set = 'train'* contains the latest transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem:\n",
    "Given a user and their latest order, predict how long it will be until the next order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a table with overall features for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.user_features AS\n",
    "    SELECT\n",
    "        user_id,\n",
    "        COUNT(order_id) AS nr_orders,\n",
    "        SUM(days_since_prior_order) AS user_lifetime,\n",
    "        COALESCE(COUNT(order_id) / NULLIF(SUM(days_since_prior_order), 0), 1) AS nr_orders_per_day,\n",
    "        AVG(days_since_prior_order) AS avg_nr_days_between_orders,\n",
    "        COUNT(CASE WHEN order_dow = 0 THEN order_id END) AS nr_orders_saturday,\n",
    "        COUNT(CASE WHEN order_dow = 1 THEN order_id END) AS nr_orders_sunday,\n",
    "        COUNT(CASE WHEN order_dow = 2 THEN order_id END) AS nr_orders_monday,\n",
    "        COUNT(CASE WHEN order_dow = 3 THEN order_id END) AS nr_orders_tuesday,\n",
    "        COUNT(CASE WHEN order_dow = 4 THEN order_id END) AS nr_orders_wednesday,\n",
    "        COUNT(CASE WHEN order_dow = 5 THEN order_id END) AS nr_orders_thursday,\n",
    "        COUNT(CASE WHEN order_dow = 6 THEN order_id END) AS nr_orders_friday,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN order_id END) AS nr_orders_morning,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN order_id END) AS nr_orders_afternoon,\n",
    "        COUNT(CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN order_id END) AS nr_orders_evening,\n",
    "        COUNT(CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN order_id END) AS nr_orders_night \n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    WHERE eval_set = 'prior' -- Only use the prior data for training features\n",
    "    GROUP BY\n",
    "        user_id\n",
    "    \"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.user_features\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(user_features)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a table with features for latest transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_transaction=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.latest_transaction AS\n",
    "    SELECT\n",
    "        user_id,\n",
    "        ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY order_number DESC) AS order_rank,\n",
    "        days_since_prior_order,\n",
    "        CASE WHEN order_dow = 0 THEN 1 ELSE 0 END AS is_saturday_order,\n",
    "        CASE WHEN order_dow = 1 THEN 1 ELSE 0 END AS is_sunday_order,\n",
    "        CASE WHEN order_dow = 2 THEN 1 ELSE 0 END AS is_monday_order,\n",
    "        CASE WHEN order_dow = 3 THEN 1 ELSE 0 END AS is_tuesday_order,\n",
    "        CASE WHEN order_dow = 4 THEN 1 ELSE 0 END AS is_wednesday_order,\n",
    "        CASE WHEN order_dow = 5 THEN 1 ELSE 0 END AS is_thursday_order,\n",
    "        CASE WHEN order_dow = 6 THEN 1 ELSE 0 END AS is_friday_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 5 AND 11 THEN 1 ELSE 0 END AS is_morning_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 12 AND 17 THEN 1 ELSE 0 END AS is_afternoon_order,\n",
    "        CASE WHEN order_hour_of_day BETWEEN 18 AND 22 THEN 1 ELSE 0 END AS is_evening_order,\n",
    "        CASE WHEN order_hour_of_day > 22 OR order_hour_of_day < 5 THEN 1 ELSE 0 END AS is_night_order\n",
    "    FROM instacart_{LAB_ID}.orders\n",
    "    WHERE eval_set = 'prior'\n",
    "\"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.latest_transaction\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(latest_transaction)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a table with features and target label used for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=\"\"\"\n",
    "    CREATE TABLE instacart_{LAB_ID}.feature_set AS\n",
    "    SELECT\n",
    "        -- Observation key\n",
    "        lt.user_id,\n",
    "        \n",
    "        -- Features about last order\n",
    "        lt.is_saturday_order,\n",
    "        lt.is_sunday_order,\n",
    "        lt.is_monday_order,\n",
    "        lt.is_tuesday_order,\n",
    "        lt.is_wednesday_order,\n",
    "        lt.is_thursday_order,\n",
    "        lt.is_friday_order,\n",
    "        lt.is_morning_order,\n",
    "        lt.is_afternoon_order,\n",
    "        lt.is_evening_order,\n",
    "        lt.is_night_order,\n",
    "        lt.days_since_prior_order,\n",
    "        \n",
    "        -- Features about user\n",
    "        uf.nr_orders,\n",
    "        uf.user_lifetime,\n",
    "        uf.nr_orders_per_day,\n",
    "        uf.avg_nr_days_between_orders,\n",
    "        uf.nr_orders_saturday,\n",
    "        uf.nr_orders_sunday,\n",
    "        uf.nr_orders_monday,\n",
    "        uf.nr_orders_tuesday,\n",
    "        uf.nr_orders_wednesday,\n",
    "        uf.nr_orders_thursday,\n",
    "        uf.nr_orders_friday,\n",
    "        uf.nr_orders_morning,\n",
    "        uf.nr_orders_afternoon,\n",
    "        uf.nr_orders_evening,\n",
    "        uf.nr_orders_night,\n",
    "        \n",
    "        -- Target label\n",
    "        target.days_since_prior_order AS days_to_next_order,\n",
    "        \n",
    "        -- Train vs test\n",
    "        RAND() <= 0.8 AS is_train\n",
    "    FROM instacart_{LAB_ID}.latest_transaction lt\n",
    "    INNER JOIN instacart_{LAB_ID}.user_features uf ON uf.user_id = lt.user_id\n",
    "    INNER JOIN instacart_{LAB_ID}.orders target ON target.user_id = lt.user_id \n",
    "        AND target.eval_set = 'train' \n",
    "    WHERE lt.order_rank = 1 -- Take last transaction in prior set\n",
    "\"\"\".format(LAB_ID=LAB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop if it already exists\n",
    "query_drop = client.query(\"DROP TABLE IF EXISTS instacart_{LAB_ID}.feature_set\".format(LAB_ID=LAB_ID))\n",
    "query_drop.result()  # Wait for finish\n",
    "print(\"Dropped table\")\n",
    "\n",
    "# Create table\n",
    "query_create = client.query(feature_set)\n",
    "query_create.result()  # Wait for finish\n",
    "print(\"Created table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check tables are there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bigquery](img/instacart_bigquery.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the training data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.feature_set\n",
    "    WHERE is_train\n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create training dataset for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Some variables\n",
    "drop_columns = ['user_id']  # Columns not to include in training\n",
    "target_label = 'days_to_next_order'\n",
    "\n",
    "# Create dataset\n",
    "features = df.drop(drop_columns + [target_label], axis=1)\n",
    "labels = df[target_label]\n",
    "training_dataset = xgb.DMatrix(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model1 = xgb.train({}, training_dataset, 10)\n",
    "model2 = xgb.train({}, training_dataset, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Evaluate 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read evaluation data\n",
    "df_eval = client.query(\n",
    "\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM instacart_{LAB_ID}.feature_set\n",
    "    WHERE NOT is_train \n",
    "\"\"\".format(LAB_ID=LAB_ID)\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation dataset\n",
    "features_eval = df_eval.drop(drop_columns + [target_label], axis=1)\n",
    "labels_eval = df_eval[target_label]\n",
    "eval_dataset = xgb.DMatrix(features_eval, labels_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with models on evaluation dataset\n",
    "prediction_model1 = model1.predict(eval_dataset)\n",
    "prediction_model2 = model2.predict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_model1 = mean_squared_error(labels_eval, prediction_model1, squared=False)\n",
    "rmse_model2 = mean_squared_error(labels_eval, prediction_model2, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pick best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Model 1: 9.1836\n",
      "RMSE Model 2: 9.1771\n",
      "Best model is Model 2\n"
     ]
    }
   ],
   "source": [
    "# Pick best performing model\n",
    "print(\"RMSE Model 1: %0.4f\" % rmse_model1)\n",
    "print(\"RMSE Model 2: %0.4f\" % rmse_model2)\n",
    "if rmse_model1 <= rmse_model2:\n",
    "    print(\"Best model is Model 1\")\n",
    "    best_model = model1\n",
    "else:\n",
    "    print(\"Best model is Model 2\")\n",
    "    best_model = model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the model to the disk on this jupyterlab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from google.cloud import storage\n",
    "model_name = 'model.bst'\n",
    "best_model.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create a folder in Google Cloud Storage to upload the model to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for the model in GCS\n",
    "storage_client = storage.Client(project=PROJECT)\n",
    "bucket = storage_client.bucket(bucket_name=BUCKET)\n",
    "\n",
    "folder = bucket.blob('instacart/model/')\n",
    "folder.upload_from_string('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Upload the model to [Google Cloud Storage](https://console.cloud.google.com/storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the model to GCS\n",
    "blob = bucket.blob('instacart/model/{MODEL_NAME}'.format(MODEL_NAME=model_name))\n",
    "blob.upload_from_filename(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_model.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some variables needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"gs://{BUCKET}/instacart/model\".format(BUCKET=BUCKET)\n",
    "MODEL_NAME = \"xgboost_model2_{LAB_ID}\".format(LAB_ID=LAB_ID)\n",
    "VERSION = \"v1_0_0\"\n",
    "FRAMEWORK = \"xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MODEL_PATH'] = MODEL_PATH\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['VERSION'] = VERSION\n",
    "os.environ['FRAMEWORK'] = FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a model and a version of the model in AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://europe-west1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/avaus-academy/models/xgboost_model2_instacart_sebastian_test].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create placeholder for model\n",
    "gcloud ai-platform models create $MODEL_NAME --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://europe-west1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a version of the model\n",
    "gcloud ai-platform versions create $VERSION \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin $MODEL_PATH \\\n",
    "  --region $REGION \\\n",
    "  --runtime-version=2.4 \\\n",
    "  --framework $FRAMEWORK \\\n",
    "  --python-version=3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2021-08-09T14:39:23Z'\n",
      "deploymentUri: gs://instacart-sebastian-test/instacart/model\n",
      "etag: l8SWSQu2LDM=\n",
      "framework: XGBOOST\n",
      "isDefault: true\n",
      "machineType: n1-standard-2\n",
      "name: projects/avaus-academy/models/xgboost_model2_instacart_sebastian_test/versions/v1_0_0\n",
      "pythonVersion: '3.7'\n",
      "runtimeVersion: '2.4'\n",
      "state: READY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://europe-west1-ml.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Check model\n",
    "gcloud ai-platform versions describe $VERSION \\\n",
    "  --model $MODEL_NAME --region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check models in AI platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](img/instacart_ai_platform.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "creds, project = google.auth.default()\n",
    "\n",
    "# creds.valid is False, and creds.token is None\n",
    "# Need to refresh credentials to populate those\n",
    "\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "token = creds.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://europe-west1-ml.googleapis.com/v1/projects/avaus-academy/models/xgboost_model2_instacart_sebastian_test/versions/v1_0_0:predict\n",
      "b'{\"predictions\": [10.727479934692383, 24.83864402770996]}'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "# Construct the API url\n",
    "api = \"https://{REGION}-ml.googleapis.com/v1/projects/{PROJECT}/models/{MODEL_NAME}/versions/{VERSION}:predict\"\\\n",
    "    .format(REGION=REGION, PROJECT=PROJECT, MODEL_NAME=MODEL_NAME, VERSION=VERSION)\n",
    "print(api)\n",
    "# Header and data field of HTTP request\n",
    "headers = {'Authorization': 'Bearer ' + token }\n",
    "data = {\n",
    "  'instances': [\n",
    "      # True value of target label \"days_to_next_order\": 8.0\n",
    "      [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 8.0, 20, 126.0, 0.15873015873015872, 6.631578947368422, 2, 1, 1, 2, 6, 3, 5, 6, 14, 0, 0],\n",
    "      \n",
    "      # True value of target label \"days_to_next_order\": 18.0\n",
    "      [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 30.0, 3, 60.0, 0.05, 30.0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0]\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Call the API\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up what we just did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Delete the version of the model and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://europe-west1-ml.googleapis.com/]\n",
      "This will delete version [v1_0_0]...\n",
      "\n",
      "Do you want to continue (Y/n)?  Please enter 'y' or 'n':  \n",
      "Deleting version [v1_0_0]......\n",
      "...............................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform versions delete $VERSION --model=$MODEL_NAME --region=$REGION\n",
    "gcloud ai-platform models delete $MODEL_NAME --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Delete the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = client.delete_dataset(dataset, delete_contents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Delete bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://instacart-sebastian-test/instacart/aisles.csv#1628519874227084...\n",
      "Removing gs://instacart-sebastian-test/instacart/departments.csv#1628519874222873...\n",
      "Removing gs://instacart-sebastian-test/instacart/model/#1628519918891043...     \n",
      "Removing gs://instacart-sebastian-test/instacart/model/model.bst#1628519921200362...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://instacart-sebastian-test/instacart/order_products__prior.csv#1628519874255209...\n",
      "Removing gs://instacart-sebastian-test/instacart/order_products__train.csv#1628519874222768...\n",
      "Removing gs://instacart-sebastian-test/instacart/orders.csv#1628519874227162... \n",
      "Removing gs://instacart-sebastian-test/instacart/products.csv#1628519874377305...\n",
      "/ [8 objects]                                                                   \n",
      "Operation completed over 8 objects.                                              \n",
      "Removing gs://instacart-sebastian-test/...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil rm -r gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Shutdown this jupyterlab instance "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
